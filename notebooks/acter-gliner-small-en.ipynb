{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-kovalch/acter-ner/blob/main/notebooks/acter-gliner-small-en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5X8eBFzlToi"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/r-kovalch/acter-ner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AylaRT/ACTER"
      ],
      "metadata": {
        "id": "anL-YTxVlmw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ACTER"
      ],
      "metadata": {
        "id": "IfCPdbitmcnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/acter-ner/term_extractor"
      ],
      "metadata": {
        "id": "U0nNt6v-mJi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "tKm-vAEvmQW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash combine_corpora_gliner.sh"
      ],
      "metadata": {
        "id": "1WlGm-kRl9tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp train_full.tsv train_full.jsonl && \\\n",
        "  cp test_full.tsv test_full.jsonl && \\\n",
        "  cp val_full.tsv val_full.jsonl"
      ],
      "metadata": {
        "id": "F2fzkGJ2tval"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install -U \"gliner>=0.2.19\" \"transformers>=4.51.0\" \\\n",
        "               datasets accelerate evaluate --quiet\n"
      ],
      "metadata": {
        "id": "zZSpJesbrg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.  Imports\n",
        "from datasets import load_dataset\n",
        "from gliner import GLiNER\n",
        "from gliner.training import Trainer, TrainingArguments\n",
        "from gliner.data_processing import GLiNERDataset, WordsSplitter\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding   # <-- key\n",
        "import evaluate, torch, random, itertools, json\n",
        "\n",
        "# 2.  Load ACTER JSONL\n",
        "raw = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\"train\": \"./train_full.jsonl\",\n",
        "                \"validation\": \"./test_full.jsonl\"},\n",
        ")\n",
        "\n",
        "# 3.  Convert char-level spans  âžœ  GLiNER format\n",
        "LABEL_SET = set()\n",
        "def to_gliner(ex):\n",
        "    tokens, char2tok, off = [], {}, 0\n",
        "    for i, tok in enumerate(ex[\"text\"].split()):\n",
        "        tokens.append(tok)\n",
        "        char2tok.update({off + j: i for j in range(len(tok))})\n",
        "        off += len(tok) + 1\n",
        "    ner = []\n",
        "    for ent in ex[\"entities\"]:\n",
        "        s = char2tok.get(ent[\"start\"]); e = char2tok.get(ent[\"end\"] - 1)\n",
        "        if s is not None and e is not None:\n",
        "            lbl = ent[\"label\"].lower()\n",
        "            ner.append([s, e, lbl]); LABEL_SET.add(lbl)\n",
        "    item = {\"tokenized_text\": tokens, \"ner\": ner}\n",
        "    if not ner:                               # sentences without entities\n",
        "        item[\"label\"] = sorted(LABEL_SET)     # see issue #139\n",
        "    return item\n",
        "\n",
        "train_py = [to_gliner(x) for x in raw[\"train\"]]\n",
        "dev_py   = [to_gliner(x) for x in raw[\"validation\"]]\n",
        "labels   = sorted(LABEL_SET)\n",
        "\n",
        "# 4.  Wrap with GLiNERDataset\n",
        "model     = GLiNER.from_pretrained(\"gliner-community/gliner_small-v2.5\")\n",
        "tok       = model.data_processor.transformer_tokenizer\n",
        "splitter  = WordsSplitter(model.config.words_splitter_type)\n",
        "\n",
        "train_ds = GLiNERDataset(train_py, model.config, tok, splitter,\n",
        "                         entities=labels)\n",
        "dev_ds   = GLiNERDataset(dev_py,  model.config, tok, splitter,\n",
        "                         entities=labels)\n",
        "\n",
        "# 5.  Use *DataCollatorWithPadding* (NOT DataCollator)\n",
        "collator = DataCollatorWithPadding(model.config)\n",
        "\n",
        "# 6.  TrainingArguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"gliner_acter_ft\",\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    remove_unused_columns=False,   # keep custom keys like 'label'\n",
        ")\n",
        "\n",
        "# 7.  Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=dev_ds,\n",
        "    tokenizer=tok,                 # still accepted; FutureWarning OK\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(\"gliner_acter_ft\")\n"
      ],
      "metadata": {
        "id": "K52AmYesowiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ],
      "metadata": {
        "id": "QWMFPDrSBFQ-"
      }
    }
  ]
}