{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57193036d523456292dbf7c9f121bd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e70f2768613c40e6b899eb654c66e346",
              "IPY_MODEL_9f4302c68cf148e3bb8cdcb6adc8c068",
              "IPY_MODEL_41e3d6b6980f4361b62a975d17d7d3e1"
            ],
            "layout": "IPY_MODEL_3f7d5eca7ec54beaa8524bcfb8fb5cac"
          }
        },
        "e70f2768613c40e6b899eb654c66e346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4436f72068e84a7f97017826c5403d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_d7834d7fa2af4523af10468637001907",
            "value": "Fetching 5 files: 100%"
          }
        },
        "9f4302c68cf148e3bb8cdcb6adc8c068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321c16863bd5426b8b4ee40d913aef5b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9abea3571724748954e1ce098e613bd",
            "value": 5
          }
        },
        "41e3d6b6980f4361b62a975d17d7d3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1497f738f5104abba90fd62488196fd9",
            "placeholder": "​",
            "style": "IPY_MODEL_c1fba06a10e8465297c3991897a902ab",
            "value": " 5/5 [00:00&lt;00:00, 560.05it/s]"
          }
        },
        "3f7d5eca7ec54beaa8524bcfb8fb5cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4436f72068e84a7f97017826c5403d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7834d7fa2af4523af10468637001907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321c16863bd5426b8b4ee40d913aef5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9abea3571724748954e1ce098e613bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1497f738f5104abba90fd62488196fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fba06a10e8465297c3991897a902ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-kovalch/acter-ner/blob/main/notebooks/acter-gliner-large-v2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5X8eBFzlToi",
        "outputId": "cc8c059d-9240-40bb-8855-1698e12edb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'acter-ner'...\n",
            "remote: Enumerating objects: 546, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 546 (delta 25), reused 6 (delta 5), pack-reused 491 (from 1)\u001b[K\n",
            "Receiving objects: 100% (546/546), 4.58 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/r-kovalch/acter-ner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AylaRT/ACTER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anL-YTxVlmw4",
        "outputId": "bc153462-96e5-471f-a6a3-4e0eccadb2d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ACTER'...\n",
            "remote: Enumerating objects: 5448, done.\u001b[K\n",
            "remote: Counting objects: 100% (5448/5448), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3304/3304), done.\u001b[K\n",
            "remote: Total 5448 (delta 2684), reused 4893 (delta 2132), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5448/5448), 11.90 MiB | 12.00 MiB/s, done.\n",
            "Resolving deltas: 100% (2684/2684), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ACTER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfCPdbitmcnO",
        "outputId": "ffed4f85-1d49-4dd0-b8e5-b6d006ebc5a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ACTER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/acter-ner/term_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0nNt6v-mJi-",
        "outputId": "d352b96b-c2aa-430e-88e2-2d14bada8f6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/acter-ner/term_extractor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKm-vAEvmQW9",
        "outputId": "0bb0b048-b2f9-4fcb-f52e-eef41d3b1c28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ner/datasets/train_full.tsv train.tsv && \\\n",
        "  cp /content/drive/MyDrive/ner/datasets/val_full.tsv val.tsv"
      ],
      "metadata": {
        "id": "_4sNiekdkhDb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def tsv_iob_to_json(tsv_path, json_path):\n",
        "    sentences = []\n",
        "    tokens, tags = [], []\n",
        "    with open(tsv_path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            if not line.strip():\n",
        "                if tokens:\n",
        "                    sentences.append((tokens, tags))\n",
        "                    tokens, tags = [], []\n",
        "                continue\n",
        "            tok, tag = line.split(\"\\t\")[:2]\n",
        "            tokens.append(tok)\n",
        "            tags.append(tag)\n",
        "    if tokens:\n",
        "        sentences.append((tokens, tags))\n",
        "    json_records = []\n",
        "    for toks, tgs in sentences:\n",
        "        ner_spans = []\n",
        "        i = 0\n",
        "        while i < len(tgs):\n",
        "            tag = tgs[i]\n",
        "            if tag.startswith(\"B-\"):\n",
        "                label = tag[2:]\n",
        "                start = i\n",
        "                i += 1\n",
        "                while i < len(tgs) and tgs[i] == f\"I-{label}\":\n",
        "                    i += 1\n",
        "                ner_spans.append([start, i-1, label])\n",
        "            else:\n",
        "                i += 1\n",
        "        json_records.append({\"tokenized_text\": toks, \"ner\": ner_spans})\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as out_file:\n",
        "        json.dump(json_records, out_file, ensure_ascii=False, indent=2)\n",
        "\n",
        "tsv_iob_to_json(\"train.tsv\", \"train.json\")\n",
        "tsv_iob_to_json(\"val.tsv\", \"val.json\")\n"
      ],
      "metadata": {
        "id": "UYCtgM_MjqtW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U \"gliner>=0.2.19\" \"transformers>=4.51.0\" \\\n",
        "               datasets accelerate evaluate seqeval --quiet"
      ],
      "metadata": {
        "id": "zZSpJesbrg_Q",
        "outputId": "fd03a90f-84c6-4f9a-dc80-dcf0b8b01255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, json, random\n",
        "from datasets import load_dataset\n",
        "from gliner import GLiNER\n",
        "from gliner.training import Trainer, TrainingArguments\n",
        "from gliner.data_processing import GLiNERDataset, WordsSplitter\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\n",
        "import torch, re, random, itertools, json\n",
        "from collections import Counter\n",
        "from transformers import EarlyStoppingCallback, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "eVaU5KngAKv2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"train.json\"\n",
        "test_path = \"val.json\"\n",
        "\n",
        "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "print('Train dataset size:', len(train_data))\n",
        "\n",
        "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "print('Test dataset size:', len(test_data))\n",
        "\n",
        "random.shuffle(train_data)\n",
        "print('Train data is shuffled...')\n",
        "\n",
        "train_dataset = train_data[:int(len(train_data) * 0.2)]\n",
        "test_dataset = test_data\n",
        "\n",
        "print('Dataset is prepared')"
      ],
      "metadata": {
        "id": "oZIB8xZAuFRY",
        "outputId": "88acb8d8-4b6d-4f3d-e005-927f9ca71a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 11343\n",
            "Test dataset size: 2833\n",
            "Train data is shuffled...\n",
            "Dataset is prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'gliner_large-v2'\n",
        "EXPERIMENT_NAME = 'rerank_max'\n",
        "\n",
        "model = GLiNER.from_pretrained(f\"urchade/{MODEL_NAME}\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "data_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)"
      ],
      "metadata": {
        "id": "brqp0SYqmU4A",
        "outputId": "fc9f01d1-13db-4871-858d-d06ecacf76eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "57193036d523456292dbf7c9f121bd46",
            "e70f2768613c40e6b899eb654c66e346",
            "9f4302c68cf148e3bb8cdcb6adc8c068",
            "41e3d6b6980f4361b62a975d17d7d3e1",
            "3f7d5eca7ec54beaa8524bcfb8fb5cac",
            "4436f72068e84a7f97017826c5403d1d",
            "d7834d7fa2af4523af10468637001907",
            "321c16863bd5426b8b4ee40d913aef5b",
            "d9abea3571724748954e1ce098e613bd",
            "1497f738f5104abba90fd62488196fd9",
            "c1fba06a10e8465297c3991897a902ab"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57193036d523456292dbf7c9f121bd46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 500\n",
        "log_steps = 50\n",
        "batch_size = 24\n",
        "data_size = len(train_dataset)\n",
        "num_batches = data_size // batch_size\n",
        "num_epochs = max(1, num_steps // num_batches)\n",
        "\n",
        "GLINER_THRESHOLD = 0.35\n",
        "labels=sorted([\"TERM\"])\n",
        "\n",
        "\n",
        "_PRF_RE = re.compile(\n",
        "    r\"P:\\s*([0-9.]+)%\\s*R:\\s*([0-9.]+)%\\s*F1:\\s*([0-9.]+)%\", re.I\n",
        ")\n",
        "\n",
        "def compute_metrics(_eval_pred):\n",
        "    \"\"\"\n",
        "    Handles   model.evaluate() -> (output_str, f1)\n",
        "    where output_str looks like:  \"P: 78.42%\\\\tR: 71.95%\\\\tF1: 75.03%\\\\n\"\n",
        "    Returns ents_p / ents_r / ents_f (in %) and 'score' = F1 (0-1).\n",
        "    \"\"\"\n",
        "    out_str, f1 = model.evaluate(                 # <- your Evaluator method\n",
        "        test_dataset,\n",
        "        threshold=GLINER_THRESHOLD,\n",
        "        entity_types=labels\n",
        "    )\n",
        "\n",
        "    # -------- extract P and R from the string -----------------------------\n",
        "    m = _PRF_RE.search(out_str)\n",
        "    if not m:\n",
        "        raise ValueError(f\"Cannot parse PRF from: {out_str!r}\")\n",
        "    p, r = (float(m.group(1)), float(m.group(2)))   # already %\n",
        "    # f1 returned by evaluate() is 0-1, convert to %\n",
        "    f1_pct = f1 * 100\n",
        "\n",
        "    return {\n",
        "        \"ents_p\": p,\n",
        "        \"ents_r\": r,\n",
        "        \"ents_f\": f1_pct,\n",
        "        \"score\":  f1,           # 0-1 scalar for best-model tracking\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"models\",\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type=\"linear\", #cosine\n",
        "    warmup_ratio=0.1,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_steps = log_steps,\n",
        "    logging_steps = log_steps,\n",
        "    save_total_limit=10,\n",
        "    dataloader_num_workers = 0,\n",
        "    use_cpu = False,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    # label_names=[\"ner_labels\"],\n",
        "    fp16=False,\n",
        "    dataloader_drop_last=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=model.data_processor.transformer_tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.can_return_loss = True\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "K52AmYesowiq",
        "outputId": "5b1473ef-2bc8-42f7-b869-ddcdac024f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6f1ed11f778f>:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/470 01:43 < 06:24, 0.96 it/s, Epoch 1.06/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Ents P</th>\n",
              "      <th>Ents R</th>\n",
              "      <th>Ents F</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>100.615200</td>\n",
              "      <td>58.672890</td>\n",
              "      <td>61.370000</td>\n",
              "      <td>80.230000</td>\n",
              "      <td>69.539400</td>\n",
              "      <td>0.695394</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 96/118 00:18 < 00:04, 5.05 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # path to the best-loss checkpoint\n",
        "# best_path = \"/content/drive/MyDrive/ucu/ner/gliner_acter_en_large_v2_5_ft/checkpoint-284\"\n",
        "# print(\"Best checkpoint:\", best_path)\n",
        "# best_model = GLiNER.from_pretrained(best_path).to(\"cuda\")\n",
        "# out_str, f1 = best_model.evaluate(\n",
        "#     dev_py,\n",
        "#     threshold=0.35,\n",
        "#     entity_types=labels,\n",
        "#     batch_size=1         # adjust until it fits\n",
        "# )\n",
        "# print(out_str)          # P: 65.06%\tR: 88.52%\tF1: 75.00%\n"
      ],
      "metadata": {
        "id": "2oi6KJZT08r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ],
      "metadata": {
        "id": "QWMFPDrSBFQ-"
      }
    }
  ]
}