{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP1aPREzrBMdBtp0jhcuP7v",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Reennon/acter-ner/blob/colab-dry-run/notebooks/dry-run\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5X8eBFzlToi",
    "outputId": "92de2a74-a4a4-4c3e-ed34-5dd29d00a313"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Reennon/acter-ner"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/AylaRT/ACTER"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anL-YTxVlmw4",
    "outputId": "a56a4fb4-fa48-4ea6-99ad-61725ca88791"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/ACTER"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfCPdbitmcnO",
    "outputId": "1af0c244-dbad-437d-b612-a2d56b86910b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/acter-ner/term_extractor"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0nNt6v-mJi-",
    "outputId": "065f833b-da3b-4607-c015-01cff5395b79"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKm-vAEvmQW9",
    "outputId": "bbaee50f-f9ae-40cb-8adb-7fcbeaa75c6e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!bash combine_corpora.sh"
   ],
   "metadata": {
    "id": "1WlGm-kRl9tu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!rm train_full.tsv && \\\n",
    "  mv /content/drive/MyDrive/ucu/ner/datasets/train_cvalue_original.tsv train_full.tsv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell X – programmatic IOB‐TSV → DocBin conversion for multiple splits\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Span\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Initialize blank pipeline (no models loaded)\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# 2) List of (input TSV, desired output .spacy) pairs\n",
    "splits = {\n",
    "    \"train_full.tsv\":   \"train_full.spacy\",\n",
    "    \"test_full.tsv\": \"test_full.spacy\",\n",
    "}\n",
    "\n",
    "# 3) Prepare output directory\n",
    "out_dir = Path(\"output\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 4) Conversion loop\n",
    "for tsv_name, spacy_name in splits.items():\n",
    "    tsv_path = Path(tsv_name)\n",
    "    if not tsv_path.exists():\n",
    "        print(f\"⚠️  Skipping missing {tsv_name}\")\n",
    "        continue\n",
    "\n",
    "    docbin = DocBin(store_user_data=True)\n",
    "    doc_count = ent_count = 0\n",
    "\n",
    "    # read token-per-line, blank lines separate sentences → we group N sentences into one Doc\n",
    "    # Here we’ll group every sentence as its own Doc (n_sents=1)\n",
    "    words, labels = [], []\n",
    "    with tsv_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if words:\n",
    "                    doc = spacy.tokens.Doc(nlp.vocab, words=words)\n",
    "                    ents = []\n",
    "                    # scan IOB labels to recover Span(start, end)\n",
    "                    start = None\n",
    "                    for i, tag in enumerate(labels):\n",
    "                        if tag.startswith(\"B\"):\n",
    "                            if start is not None:\n",
    "                                ents.append(Span(doc, start, i, label=\"TERM\"))\n",
    "                            start = i\n",
    "                        elif tag.startswith(\"I\"):\n",
    "                            # continuation\n",
    "                            continue\n",
    "                        else:  # \"O\" or other\n",
    "                            if start is not None:\n",
    "                                ents.append(Span(doc, start, i, label=\"TERM\"))\n",
    "                                start = None\n",
    "                    # catch final\n",
    "                    if start is not None:\n",
    "                        ents.append(Span(doc, start, len(labels), label=\"TERM\"))\n",
    "\n",
    "                    doc.ents = ents\n",
    "                    docbin.add(doc)\n",
    "                    doc_count += 1\n",
    "                    ent_count += len(ents)\n",
    "                    words, labels = [], []\n",
    "                continue\n",
    "\n",
    "            # parse token and IOB label (label may be \"O\" or \"B-TERM\"/\"I-TERM\")\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            tok, tag = parts\n",
    "            words.append(tok)\n",
    "            # normalize to plain \"B\"/\"I\"/\"O\"\n",
    "            if tag.startswith(\"B\"):\n",
    "                labels.append(\"B\")\n",
    "            elif tag.startswith(\"I\"):\n",
    "                labels.append(\"I\")\n",
    "            else:\n",
    "                labels.append(\"O\")\n",
    "\n",
    "        # flush last sentence if missing trailing blank line\n",
    "        if words:\n",
    "            doc = spacy.tokens.Doc(nlp.vocab, words=words)\n",
    "            ents = []\n",
    "            start = None\n",
    "            for i, tag in enumerate(labels):\n",
    "                if tag == \"B\":\n",
    "                    if start is not None:\n",
    "                        ents.append(Span(doc, start, i, label=\"TERM\"))\n",
    "                    start = i\n",
    "                elif tag == \"O\" and start is not None:\n",
    "                    ents.append(Span(doc, start, i, label=\"TERM\"))\n",
    "                    start = None\n",
    "            if start is not None:\n",
    "                ents.append(Span(doc, start, len(labels), label=\"TERM\"))\n",
    "            doc.ents = ents\n",
    "            docbin.add(doc)\n",
    "            doc_count += 1\n",
    "            ent_count += len(ents)\n",
    "\n",
    "    # write out the DocBin\n",
    "    out_path = out_dir / spacy_name\n",
    "    docbin.to_disk(out_path)\n",
    "    print(f\"✅ Converted {tsv_name} → {out_path} \"\n",
    "          f\"({doc_count} docs, {ent_count} entities)\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K52AmYesowiq",
    "outputId": "f447caa6-c77d-4993-bd79-f8a47bdab4a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir input_data && \\\n",
    "  mv output/train_full.spacy input_data/train_full.spacy && \\\n",
    "  mv output/test_full.spacy input_data/test_full.spacy && \\\n",
    "  mkdir -p /content/drive/MyDrive/ucu/ner/output/acter-cvalue-conf2-25-roberta-large-en"
   ],
   "metadata": {
    "id": "MW4g58A-pgXk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install 'spacy[transformers]' -q"
   ],
   "metadata": {
    "collapsed": true,
    "id": "hhr_t0BEp5Qs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!spacy train configs/config_base.cfg  --gpu-id 0 --output /content/drive/MyDrive/ucu/ner/output/acter-cvalue-conf2-25-roberta-large-en"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaYbLOFUoqhx",
    "outputId": "81f6b7f8-59db-4bbc-cf5c-4830b8bd1cc8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
