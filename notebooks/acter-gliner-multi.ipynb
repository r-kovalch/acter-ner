{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-kovalch/acter-ner/blob/main/notebooks/acter-gliner-multi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5X8eBFzlToi"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/r-kovalch/acter-ner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AylaRT/ACTER"
      ],
      "metadata": {
        "id": "anL-YTxVlmw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ACTER"
      ],
      "metadata": {
        "id": "IfCPdbitmcnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/acter-ner/term_extractor"
      ],
      "metadata": {
        "id": "U0nNt6v-mJi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "tKm-vAEvmQW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash combine_corpora_gliner_multi.sh"
      ],
      "metadata": {
        "id": "1WlGm-kRl9tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp train_full.tsv train_full.jsonl && \\\n",
        "  cp test_full.tsv test_full.jsonl && \\\n",
        "  cp val_full.tsv val_full.jsonl"
      ],
      "metadata": {
        "id": "F2fzkGJ2tval"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install -U \"gliner>=0.2.19\" \"transformers>=4.51.0\" \\\n",
        "               datasets accelerate evaluate seqeval --quiet"
      ],
      "metadata": {
        "id": "zZSpJesbrg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "spqi0xwdJIh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from gliner import GLiNER\n",
        "from gliner.data_processing import GLiNERDataset, WordsSplitter\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding\n",
        "from gliner.training import Trainer, TrainingArguments\n",
        "import evaluate\n",
        "import torch\n",
        "from transformers import EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "eVaU5KngAKv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLINER_THRESHOLD=0.35\n",
        "GLINER_MODEL=\"urchade/gliner_multi-v2.1\"\n",
        "\n",
        "\n",
        "# 2.  Load ACTER JSONL\n",
        "raw = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\"train\": \"./train_full.jsonl\",\n",
        "                \"validation\": \"./test_full.jsonl\"},\n",
        ")\n",
        "\n",
        "# 3.  Convert char-level spans  ➜  GLiNER format\n",
        "LABEL_SET = set()\n",
        "def to_gliner(ex):\n",
        "    tokens, char2tok, off = [], {}, 0\n",
        "    for i, tok in enumerate(ex[\"text\"].split()):\n",
        "        tokens.append(tok)\n",
        "        char2tok.update({off + j: i for j in range(len(tok))})\n",
        "        off += len(tok) + 1\n",
        "    ner = []\n",
        "    for ent in ex[\"entities\"]:\n",
        "        s = char2tok.get(ent[\"start\"]); e = char2tok.get(ent[\"end\"] - 1)\n",
        "        if s is not None and e is not None:\n",
        "            lbl = ent[\"label\"].lower()\n",
        "            ner.append([s, e, lbl]); LABEL_SET.add(lbl)\n",
        "    item = {\"tokenized_text\": tokens, \"ner\": ner}\n",
        "    if not ner:                               # sentences without entities\n",
        "        item[\"label\"] = sorted(LABEL_SET)     # see issue #139\n",
        "    return item\n",
        "\n",
        "train_py = [to_gliner(x) for x in raw[\"train\"]]\n",
        "dev_py   = [to_gliner(x) for x in raw[\"validation\"]]\n",
        "labels   = sorted(LABEL_SET)\n",
        "\n",
        "# 4.  Wrap with GLiNERDataset\n",
        "model     = GLiNER.from_pretrained(GLINER_MODEL)\n",
        "tok       = model.data_processor.transformer_tokenizer\n",
        "splitter  = WordsSplitter(model.config.words_splitter_type)\n",
        "\n",
        "train_ds = GLiNERDataset(train_py, model.config, tok, splitter,\n",
        "                         entities=labels)\n",
        "dev_ds   = GLiNERDataset(dev_py,  model.config, tok, splitter,\n",
        "                         entities=labels)\n",
        "\n",
        "# 5.  Use *DataCollatorWithPadding* (NOT DataCollator)\n",
        "collator = DataCollatorWithPadding(model.config)\n",
        "\n",
        "# ---------------- 6.  compute_metrics  --------------------\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def char_to_tokens(txt):\n",
        "    \"\"\"helper: char idx ➜ token idx map for whitespace split text\"\"\"\n",
        "    m, p = {}, 0\n",
        "    for i, t in enumerate(txt.split()):\n",
        "        m.update({p + j: i for j in range(len(t))}); p += len(t) + 1\n",
        "    return m\n",
        "\n",
        "def spans_to_bio(tokens, spans, label2idx):\n",
        "    tags = [\"O\"] * len(tokens)\n",
        "    for s, e, lab in spans:\n",
        "        tags[s] = f\"B-{lab}\"\n",
        "        for i in range(s + 1, e + 1):\n",
        "            tags[i] = f\"I-{lab}\"\n",
        "    return tags\n",
        "\n",
        "import re\n",
        "\n",
        "# pre-compile once – matches “P: 78.42%    R: 71.95%    F1: 75.03%”\n",
        "_PRF_RE = re.compile(\n",
        "    r\"P:\\s*([0-9.]+)%\\s*R:\\s*([0-9.]+)%\\s*F1:\\s*([0-9.]+)%\", re.I\n",
        ")\n",
        "\n",
        "def compute_metrics(_eval_pred):\n",
        "    \"\"\"\n",
        "    Handles   model.evaluate() -> (output_str, f1)\n",
        "    where output_str looks like:  \"P: 78.42%\\\\tR: 71.95%\\\\tF1: 75.03%\\\\n\"\n",
        "    Returns ents_p / ents_r / ents_f (in %) and 'score' = F1 (0-1).\n",
        "    \"\"\"\n",
        "    out_str, f1 = model.evaluate(                 # <- your Evaluator method\n",
        "        dev_py,\n",
        "        threshold=GLINER_THRESHOLD,\n",
        "        entity_types=labels\n",
        "    )\n",
        "\n",
        "    # -------- extract P and R from the string -----------------------------\n",
        "    m = _PRF_RE.search(out_str)\n",
        "    if not m:\n",
        "        raise ValueError(f\"Cannot parse PRF from: {out_str!r}\")\n",
        "    p, r = (float(m.group(1)), float(m.group(2)))   # already %\n",
        "    # f1 returned by evaluate() is 0-1, convert to %\n",
        "    f1_pct = f1 * 100\n",
        "\n",
        "    return {\n",
        "        \"ents_p\": p,\n",
        "        \"ents_r\": r,\n",
        "        \"ents_f\": f1_pct,\n",
        "        \"score\":  f1,           # 0-1 scalar for best-model tracking\n",
        "    }\n",
        "\n",
        "\n",
        "# 6.  TrainingArguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/ucu/ner/gliner_multi\",\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=24,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=20,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    remove_unused_columns=False,   # keep custom keys like 'label'\n",
        ")\n",
        "\n",
        "# 7.  Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=dev_ds,\n",
        "    tokenizer=tok,                 # still accepted; FutureWarning OK\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=\"/content/drive/MyDrive/ucu/ner/gliner_multi_/checkpoint-226725/\")\n"
      ],
      "metadata": {
        "id": "K52AmYesowiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the best-loss checkpoint\n",
        "best_path = \"/content/drive/MyDrive/ucu/ner/gliner_multi/\"\n",
        "print(\"Best checkpoint:\", best_path)\n",
        "best_model = GLiNER.from_pretrained(best_path).to(\"cuda\")\n",
        "out_str, f1 = best_model.evaluate(\n",
        "    dev_py,\n",
        "    threshold=0.75,\n",
        "    entity_types=labels,\n",
        "    batch_size=1         # adjust until it fits\n",
        ")\n",
        "print(out_str)          # P: 65.06%\tR: 88.52%\tF1: 75.00%\n"
      ],
      "metadata": {
        "id": "2oi6KJZT08r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ],
      "metadata": {
        "id": "QWMFPDrSBFQ-"
      }
    }
  ]
}